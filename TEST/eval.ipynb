{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcec61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import html\n",
    "import re\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import sacrebleu\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = html.unescape(text)\n",
    "    text = re.sub(r'[^\\w\\s.,;:!?\\'\"-]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    return text\n",
    "\n",
    "\n",
    "def evaluate_translation_scores(json_path):\n",
    "    \"\"\"\n",
    "    Tính BLEU, SacreBLEU, METEOR, ROUGE-L, TF-IDF cosine similarity\n",
    "    giữa 'vi_pred' và 'vi_label' trong file JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Đọc dữ liệu ---\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    preds = [clean_text(item[\"vi_pred\"].strip()) for item in data]\n",
    "    refs = [clean_text(item[\"vi_label\"].strip()) for item in data]\n",
    "\n",
    "    # --- BLEU (nltk) ---\n",
    "    refs_nested = [[r.split()] for r in refs]\n",
    "    preds_tokenized = [p.split() for p in preds]\n",
    "    bleu_score = corpus_bleu(refs_nested, preds_tokenized) * 100\n",
    "\n",
    "    # --- SacreBLEU ---\n",
    "    sacre_bleu = sacrebleu.corpus_bleu(preds, [refs]).score\n",
    "\n",
    "    # --- METEOR (phải token hóa trước) ---\n",
    "    meteor_scores = [\n",
    "        meteor_score([ref.split()], pred.split())\n",
    "        for ref, pred in zip(refs, preds)\n",
    "    ]\n",
    "    avg_meteor = np.mean(meteor_scores) * 100\n",
    "\n",
    "    # --- ROUGE (dùng ROUGE-L) ---\n",
    "    rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "    rouge_scores = [rouge.score(r, p)[\"rougeL\"].fmeasure for r, p in zip(refs, preds)]\n",
    "    avg_rougeL = np.mean(rouge_scores) * 100\n",
    "\n",
    "    # --- TF-IDF cosine similarity ---\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(refs + preds)\n",
    "    n = len(refs)\n",
    "    tfidf_sims = [\n",
    "        cosine_similarity(tfidf_matrix[i], tfidf_matrix[i + n])[0][0]\n",
    "        for i in range(n)\n",
    "    ]\n",
    "    avg_tfidf_sim = np.mean(tfidf_sims) * 100\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu_score,\n",
    "        \"SacreBLEU\": sacre_bleu,\n",
    "        \"METEOR\": avg_meteor,\n",
    "        \"ROUGE-L\": avg_rougeL,\n",
    "        \"TF-IDF Cosine\": avg_tfidf_sim,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c526cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLEU': 14.969834025862633, 'SacreBLEU': 16.640343031723138, 'METEOR': 45.32174723031538, 'ROUGE-L': 51.00639431585394, 'TF-IDF Cosine': 52.23257006558488}\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_translation_scores(\"ALT_test/alt_multilingual_dataset/ALT_josn/en_vi_translations_seallm_fixed.json\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ALT_test/alt_multilingual_dataset/ALT_josn/en_vi_translations_seallm.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47fae5b",
   "metadata": {},
   "source": [
    "# COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19323bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dongh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\imports.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe23e63368214440b0a2c9e51edfa16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\dongh\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\2760a223ac957f30acfb18c8aa649b01cf1d75f2\\checkpoints\\model.ckpt`\n",
      "Lock 1769875716992 acquired on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\34ddbd64a4cd3f2d9d8a9120d3662d0bf91baead.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabbe5d2436f4305b2db1777c57a1845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 1769875716992 released on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\34ddbd64a4cd3f2d9d8a9120d3662d0bf91baead.lock\n",
      "Lock 1769875710032 acquired on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\db9af13bf09fd3028ca32be90d3fb66d5e470399.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e59032d99dd4eee984f07a9cfff518c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 1769875710032 released on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\db9af13bf09fd3028ca32be90d3fb66d5e470399.lock\n",
      "Lock 1769875714784 acquired on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\463f3414782c1c9405828c9b31bfa36dda1f45c5.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b42cc671e62421da178014c3db076dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 1769875714784 released on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\463f3414782c1c9405828c9b31bfa36dda1f45c5.lock\n",
      "Lock 1769875707296 acquired on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\8e5fb14e1352fd8fc678a7b293b63cfb5cf091f6.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a73b631bf7b46e8b0e72ad1768e16a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 1769875707296 released on C:\\Users\\dongh\\.cache\\huggingface\\hub\\.locks\\models--xlm-roberta-large\\8e5fb14e1352fd8fc678a7b293b63cfb5cf091f6.lock\n",
      "Encoder model frozen.\n",
      "c:\\Users\\dongh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ALT_test/ALT_josn/en_vi_nllb200.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m download_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnbabel/wmt22-comet-da\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m load_from_checkpoint(model_path)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALT_test/ALT_josn/en_vi_nllb200.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m     data_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 2️⃣ Chuyển sang format đúng cho COMET\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ALT_test/ALT_josn/en_vi_nllb200.json'"
     ]
    }
   ],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "import json\n",
    "\n",
    "model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "model = load_from_checkpoint(model_path)\n",
    "\n",
    "with open(\"ALT_test/ALT_josn/en_vi_nllb200.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "# 2️⃣ Chuyển sang format đúng cho COMET\n",
    "data = [\n",
    "    {\n",
    "        \"src\": item[\"en\"],\n",
    "        \"mt\": item[\"vi_pred\"],\n",
    "        \"ref\": item[\"vi_label\"]\n",
    "    }\n",
    "    for item in data_json\n",
    "]\n",
    "\n",
    "model_output = model.predict(data, batch_size=16, gpus=1)\n",
    "print (model_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
